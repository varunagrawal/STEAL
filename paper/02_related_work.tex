\section{Related Works}
% What have people done so far?
Gaussian Processes have a rich history of being used to represent robot trajectories. Seminal work by~\citet{Barfoot14rss} cast a robot trajectory as a linear time varying stochastic differential equation (LTV-SDE) the form of which allowed for the definition of an exactly sparse inverse covariance matrix (a.k.a. the precision matrix). This led to the development of GPMP2~\cite{Mukadam18ijrr} which leverages Gaussian Processes to provide a trajectory optimization and control framework.
Gaussian Processes have also been used in the context of inverse reinforcement learning. GPIRL~\citet{Levine11neurips} demonstrated the clever use of kernel methods and bayesian optimization in order to find the underlying reward function from just demonstrations.
\citet{Nguyen21arxiv} provide an excellent overview of the use of Gaussian Processes for trajectory representation, while the work of~\citet{Arduengo20arxiv} provides helpful, practical guidelines for setting up GPs in an LfD setting.
For incorporating the correlation between the different dimensions in the 6-DoF trajectory representation,~\citet{Arduengo20arxiv} recommend using multi-output Gaussian Processes~\cite{Bonilla07neurips} which we have also followed. For a complete and in-depth exposition on Gaussian Processes, we refer the reader to the excellent book by~\citet{Rasmussen04book}.

For safe and stable control, many different frameworks have been proposed~\cite{Duchaine09icra}. Dynamic Movement Primitives~\cite{Ijspeert13nc} was the first approach to utilize a dynamical system for control, allowing for stability and safety analysis.
To incorporate variations in the control trajectories, Probabilistic Motion Primitives (ProMPs)~\cite{Paraschos13neurips} have been proposed and have seen tremendous success over the years
DMPs and ProMPs both have the drawback that they operate on Euclidean spaces, while our natural world is primarily non-Euclidean. To address this shortcoming,~\citet{Ratliff18arxiv} proposed Riemannian Motion Policies (RMPs) which encode both the second-degree acceleration policy of the robot and the nature of the manifold in which the policy operates.
This was further extended into a fully computation motion generation framework termed RMPflow~\cite{Cheng21tase} which is capble of efficiently and optimally combining different RMPs to provide a consistent and stable global policy.

RMPflow is however limited by the fact that it relies on hand-specifying the RMPs. Work by~\cite{Rana20corl} showed how to learn an RMP from demonstration data, which could then be directly injected into RMPflow to reproduce complex robot motions. To enable learning from a set of trajectories, in contrast to the single trajectory approach of~\cite{Rana20corl},~\citet{Rana20ldc} proposed Euclideanizing Flows which learns mapping from the manifold to an equivalent Euclidean space via the change of variables formula.
While pushing the state-of-the-art, these works still suffer from the lack of ability to generalize over sub-optimal demonstrations.
Thus, in this work, we propose to incorporate Gaussian Processes for trajectory estimation in the presence of suboptimal demonstrations, in the same vein as~\cite{Chen20corl_ssrr,Levine11neurips}.